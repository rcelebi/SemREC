{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5198,
     "status": "ok",
     "timestamp": 1659360940014,
     "user": {
      "displayName": "Shervin Mehryar",
      "userId": "08841599095409768379"
     },
     "user_tz": -120
    },
    "id": "2wnUipHPEd91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shervin/opt/anaconda3/envs/UM/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import  os\n",
    "import  re\n",
    "import glob\n",
    "\n",
    "import  pandas as pd\n",
    "import  numpy as np\n",
    "\n",
    "from src.utils import *\n",
    "from src.models import TransE, rTransE\n",
    "\n",
    "from src.env import Env\n",
    "from src.agent import DQN_Network, ExperienceReplay, process_agent_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OWL2Bench_dbs = [ { 'path' : './datasets/OWL2Bench/OWL2Bench1/',\n",
    "                'train_file'  :'_train_OWL2Bench1',\n",
    "                'test_file' : '_test_OWL2Bench1'}               ,\n",
    "                 { 'path' : './datasets/OWL2Bench/OWL2Bench2/',\n",
    "                'train_file'  :'_train_OWL2Bench2',\n",
    "                'test_file' : '_test_OWL2Bench2'} ]\n",
    "\n",
    "\n",
    "for db_ in OWL2Bench_dbs:\n",
    "    \n",
    "    path = db_['path']\n",
    "    train_file= db_['train_file']\n",
    "    test_file= db_['test_file']\n",
    "    \n",
    "    print('Running...', train_file, test_file)\n",
    "    \n",
    "    # load data\n",
    "    df_train=load_ore_files(path+train_file)\n",
    "                \n",
    "    ## subclass relations\n",
    "    data_subclass_train = df_train[df_train['p']== 'SubClassOf']\n",
    "    data_subclass_train = data_subclass_train[['s','o']].rename(columns={'s':'subClass','o':'class'})\n",
    "    transitive_classes  = pd.merge(data_subclass_train,data_subclass_train,\n",
    "                                 how='left',right_on=['subClass'],left_on=['class']\n",
    "    ).dropna(subset=['class_y'])\n",
    "    del transitive_classes['class_x']\n",
    "    transitive_classes.columns = ['class_0', 'class_1', 'class_2']\n",
    "    transitive_classes = transitive_classes.drop_duplicates(subset=['class_0', 'class_1', 'class_2'])\n",
    "    data_subclass_train_quads = transitive_classes.reset_index(drop=True)            \n",
    "      \n",
    "    ## assertion relations\n",
    "    data_assertion_train = df_train[df_train['p']== 'ClassAssertion']\n",
    "    data_assertion_train = data_assertion_train[['s','o']].rename(columns={'s':'class','o':'assertion'})\n",
    "\n",
    "    ## cross relations             \n",
    "    transitive_classes = pd.merge(data_assertion_train,data_subclass_train,\n",
    "                                 how='left',right_on=['subClass'],left_on=['class']).dropna(subset=['subClass'])\n",
    "    print(len(transitive_classes))\n",
    "    del transitive_classes['class_x']\n",
    "    transitive_classes.columns = ['assertion', 'class_0', 'class_1']\n",
    "    data_cross_quads = transitive_classes.reset_index(drop=True)\n",
    "    \n",
    "    res = prepare_crossclass_data(data_subclass_train,data_subclass_train_quads,0,\n",
    "                            data_assertion_train,1,\n",
    "                           data_cross_quads)\n",
    "    node_dict, node_count, train_trips, train_quads = res\n",
    "    \n",
    "       \n",
    "        \n",
    "    # load test data\n",
    "    df_test= load_ore_files(path+test_file)\n",
    "                 \n",
    "    data_assertion_test = df_test[df_test['p']== 'ClassAssertion']\n",
    "    data_assertion_test = data_assertion_test[['s','o']].rename(columns={'s':'class','o':'assertion'})\n",
    "    res_subcls = prepare_subclass_data(data_assertion_test,transitive_classes=None,\n",
    "                                tc1='class',tc2='assertion',r=1)\n",
    "    data_subclass_test  = df_test[df_test['p']== 'SubClassOf']\n",
    "    data_subclass_test  = data_subclass_test[['s','o']].rename(columns={'s':'subClass','o':'class'})       \n",
    "    res_assert = prepare_subclass_data(data_subclass_test,transitive_classes=None,r=0)\n",
    "\n",
    "    test_trips = res_subcls[2] + res_assert[2]\n",
    "                 \n",
    "    print(len(test_trips))\n",
    "    \n",
    "    ## tarin TransE\n",
    "    #print('')\n",
    "    #model_ORE_TransE  = TransE(node_coun=t,2)\n",
    "    #model_ORE_TransE._train(train_trips,train_quads);\n",
    "    ##model_ORE_TransE._eval(test_trips) # evaluate TransE\n",
    "    \n",
    "    # train rTransE\n",
    "    model_ORE_rTransE  = rTransE(node_count,2)\n",
    "    model_ORE_rTransE._train(train_trips,train_quads,num_epoches=200);\n",
    "    model_ORE_rTransE._eval(test_trips)  # evaluate RTransE\n",
    "    \n",
    "    env   = Env(train_trips)\n",
    "    agent = DQN_Network([60, 64, 2],lr=1e-3)\n",
    "    agent_samples = agent.train(env,\n",
    "            model_ORE_rTransE.entity_embds.detach().numpy(),\n",
    "            model_ORE_rTransE.rel_embds.detach().numpy(),\n",
    "            episodes = 20000)\n",
    "    \n",
    "    unique_agent_samples = process_agent_samples(train_quads,agent_samples)\n",
    "    updated_train_trips  = train_trips+unique_agent_samples\n",
    "    \n",
    "    update_train_trips = train_trips+unique_agent_samples\n",
    "    model_ORE_rTransE._train(update_train_trips,train_quads,num_epoches=100);\n",
    "    model_ORE_rTransE._eval(test_trips)  # evaluate RTransE\n",
    "    \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORE_dbs = [     { 'path'      : './datasets/ORE/ORE1/',\n",
    "                'train_file'  : '_train_ORE1',\n",
    "                'test_file'   : '_test_ORE1'},\n",
    "                { 'path'      : './datasets/ORE/ORE2/',\n",
    "                'train_file'  : '_train_ORE2',\n",
    "                'test_file'   : '_test_ORE2'},\n",
    "                { 'path'      : './datasets/ORE/ORE3/',\n",
    "                'train_file'  : '_train_ORE3',\n",
    "                'test_file'   : '_test_ORE3'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for db_ in ORE_dbs:\n",
    "    \n",
    "    path = db_['path']\n",
    "    train_file= db_['train_file']\n",
    "    test_file= db_['test_file']\n",
    "    \n",
    "    print('Running...', train_file, test_file)\n",
    "    \n",
    "    # load data\n",
    "    df_train= load_ore_files(path+train_file)\n",
    "                \n",
    "    ## subclass relations\n",
    "    data_subclass_train = df_train[df_train['p']== 'SubClassOf']\n",
    "    data_subclass_train = data_subclass_train[['s','o']].rename(columns={'s':'subClass','o':'class'})\n",
    "    transitive_classes  = pd.merge(data_subclass_train,data_subclass_train,\n",
    "                                 how='left',right_on=['subClass'],left_on=['class']\n",
    "    ).dropna(subset=['class_y'])\n",
    "    del transitive_classes['class_x']\n",
    "    transitive_classes.columns = ['class_0', 'class_1', 'class_2']\n",
    "    transitive_classes = transitive_classes.drop_duplicates(subset=['class_0', 'class_1', 'class_2'])\n",
    "    data_subclass_train_quads = transitive_classes.reset_index(drop=True)            \n",
    "      \n",
    "    ## assertion relations\n",
    "    data_assertion_train = df_train[df_train['p']== 'ClassAssertion']\n",
    "    data_assertion_train = data_assertion_train[['s','o']].rename(columns={'s':'class','o':'assertion'})\n",
    "\n",
    "    ## cross relations             \n",
    "    transitive_classes = pd.merge(data_assertion_train,data_subclass_train,\n",
    "                                 how='left',right_on=['subClass'],left_on=['class']).dropna(subset=['subClass'])\n",
    "    print(len(transitive_classes))\n",
    "    del transitive_classes['class_x']\n",
    "    transitive_classes.columns = ['assertion', 'class_0', 'class_1']\n",
    "    data_cross_quads = transitive_classes.reset_index(drop=True)\n",
    "    \n",
    "    res = prepare_crossclass_data(data_subclass_train,data_subclass_train_quads,0,\n",
    "                            data_assertion_train,1,\n",
    "                           data_cross_quads)\n",
    "    node_dict, node_count, train_trips, train_quads = res\n",
    "    \n",
    "       \n",
    "        \n",
    "    # load test data\n",
    "    df_test= load_ore_files(path+test_file)\n",
    "                 \n",
    "    data_assertion_test = df_test[df_test['p']== 'ClassAssertion']\n",
    "    data_assertion_test = data_assertion_test[['s','o']].rename(columns={'s':'class','o':'assertion'})\n",
    "    res_subcls = prepare_subclass_data(data_assertion_test,transitive_classes=None,\n",
    "                                tc1='class',tc2='assertion',r=1)\n",
    "    data_subclass_test  = df_test[df_test['p']== 'SubClassOf']\n",
    "    data_subclass_test  = data_subclass_test[['s','o']].rename(columns={'s':'subClass','o':'class'})       \n",
    "    res_assert = prepare_subclass_data(data_subclass_test,transitive_classes=None,r=0)\n",
    "\n",
    "    test_trips = res_subcls[2] + res_assert[2]\n",
    "                 \n",
    "    print(len(test_trips))\n",
    "    \n",
    "    ## tarin TransE\n",
    "    #print('')\n",
    "    #model_ORE_TransE  = TransE(node_count,2)\n",
    "    #model_ORE_TransE._train(train_trips,train_quads);\n",
    "    #model_ORE_TransE._eval(test_trips) # evaluate TransE\n",
    "    \n",
    "    # train rTransE\n",
    "    model_ORE_rTransE  = rTransE(node_count,2)\n",
    "    model_ORE_rTransE._train(train_trips,train_quads,num_epoches=200);\n",
    "    model_ORE_rTransE._eval(test_trips)  # evaluate RTransE\n",
    "    \n",
    "    env   = Env(train_trips)\n",
    "    agent = DQN_Network([60, 64, 2],lr=1e-3)\n",
    "    agent_samples = agent.train(env,\n",
    "            model_ORE_rTransE.entity_embds.detach().numpy(),\n",
    "            model_ORE_rTransE.rel_embds.detach().numpy(),\n",
    "            episodes = 20000)\n",
    "    \n",
    "    unique_agent_samples = process_agent_samples(train_quads,agent_samples)\n",
    "    updated_train_trips  = train_trips+unique_agent_samples\n",
    "    \n",
    "    update_train_trips = train_trips+unique_agent_samples\n",
    "    model_ORE_rTransE._train(update_train_trips,train_quads,num_epoches=100);\n",
    "    model_ORE_rTransE._eval(test_trips)  # evaluate RTransE\n",
    "    \n",
    "    print()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CaLiGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLG_dbs = [ { 'path'      : 'datasets/clg/clg_10e4/',\n",
    "                'train_file'  : 'clg_10e4-train.nt',\n",
    "                'test_file'   : 'clg_10e4-test.nt-e'},\n",
    "            { 'path'      : 'datasets/clg/clg_10e5/',\n",
    "                'train_file'  : 'clg_10e5-train.nt',\n",
    "                'test_file'   : 'clg_10e5-test.nt'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_test_batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running... clg_10e4-train.nt clg_10e4-test.nt-e\n",
      "111533 74694\n",
      "epoch 0,\t train loss 13.25\n",
      "epoch 50,\t train loss 11.49\n",
      "epoch 100,\t train loss 10.19\n",
      "epoch 150,\t train loss 8.44\n",
      "hits@1  tensor(0.4770) ,hits@10  tensor(0.6870) ,MR  tensor(16.7180) ,MRR  tensor(0.5545)\n",
      "epoch 0\tep_len 1\taverage loss 1.27\treward 1.00\tdone True\n",
      "epoch 2000\tep_len 1\taverage loss 0.43\treward 1.00\tdone True\n",
      "epoch 4000\tep_len 1\taverage loss 0.16\treward 1.00\tdone True\n",
      "epoch 6000\tep_len 1\taverage loss 0.56\treward 1.00\tdone True\n",
      "epoch 8000\tep_len 1\taverage loss 0.42\treward 1.00\tdone True\n",
      "epoch 10000\tep_len 1\taverage loss 0.22\treward 1.00\tdone True\n",
      "epoch 12000\tep_len 1\taverage loss 1.13\treward 1.00\tdone True\n",
      "epoch 14000\tep_len 1\taverage loss 0.99\treward 1.00\tdone True\n",
      "epoch 16000\tep_len 11\taverage loss 0.80\treward -0.70\tdone False\n",
      "epoch 18000\tep_len 1\taverage loss 1.04\treward 1.00\tdone True\n",
      "unique ratio: 0.80\n",
      "epoch 0,\t train loss 7.67\n",
      "epoch 50,\t train loss 6.28\n",
      "hits@1  tensor(0.5000) ,hits@10  tensor(0.6970) ,MR  tensor(16.5010) ,MRR  tensor(0.5793)\n",
      "\n",
      "Running... clg_10e5-train.nt clg_10e5-test.nt\n",
      "126246 104838\n",
      "epoch 0,\t train loss 3.96\n",
      "epoch 100,\t train loss 3.39\n",
      "epoch 150,\t train loss 4.01\n",
      "hits@1  tensor(0.6910) ,hits@10  tensor(0.7050) ,MR  tensor(19.2630) ,MRR  tensor(0.7004)\n",
      "epoch 0\tep_len 1\taverage loss 1.84\treward 1.00\tdone True\n",
      "epoch 2000\tep_len 11\taverage loss 0.24\treward -1.10\tdone False\n",
      "epoch 4000\tep_len 1\taverage loss 0.71\treward 1.00\tdone True\n",
      "epoch 6000\tep_len 1\taverage loss 0.18\treward 1.00\tdone True\n",
      "epoch 8000\tep_len 1\taverage loss 1.66\treward 1.00\tdone True\n",
      "epoch 10000\tep_len 1\taverage loss 0.13\treward 1.00\tdone True\n",
      "epoch 12000\tep_len 1\taverage loss 0.06\treward 1.00\tdone True\n",
      "epoch 14000\tep_len 11\taverage loss 0.91\treward -1.10\tdone False\n",
      "epoch 16000\tep_len 11\taverage loss 2.57\treward -0.90\tdone False\n",
      "epoch 18000\tep_len 1\taverage loss 3.91\treward 1.00\tdone True\n",
      "unique ratio: 1.00\n",
      "hits@1  tensor(0.6880) ,hits@10  tensor(0.7030) ,MR  tensor(19.5830) ,MRR  tensor(0.6986)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for db_ in CLG_dbs:\n",
    "    path = db_['path']\n",
    "    train_file= db_['train_file']\n",
    "    test_file= db_['test_file']\n",
    "    \n",
    "    print('Running...', train_file, test_file)\n",
    "    \n",
    "    df_train= load_clg_files(path+train_file)\n",
    "    data_subclass_train = df_train[df_train['p']== '<http://www.w3.org/2000/01/rdf-schema#subClassOf>']\n",
    "    data_subclass_train = data_subclass_train[['s','o']].rename(columns={'s':'subClass','o':'class'})   \n",
    "    transitive_classes= pd.merge(data_subclass_train,data_subclass_train,how='left',\n",
    "                                 right_on=['subClass'],left_on=['class']).dropna(subset=['class_y'])\n",
    "    del transitive_classes['class_x']\n",
    "    transitive_classes.columns = ['class_0', 'class_1', 'class_2']\n",
    "    transitive_classes = transitive_classes.drop_duplicates(subset=['class_0', 'class_1', 'class_2']) # drop duplicates\n",
    "    data_subclass_train_quads = transitive_classes.reset_index(drop=True)\n",
    "\n",
    "    data_type_train = df_train[df_train['p']== '<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>']\n",
    "    data_type_train = data_type_train[['s','o']].rename(columns={'s':'type','o':'class'})   \n",
    "\n",
    "    transitive_classes = pd.merge(data_type_train,data_subclass_train,\n",
    "                                     how='left',left_on=['class'],right_on=['subClass']).dropna(subset=['class_y'])\n",
    "    del transitive_classes['class_x']\n",
    "    transitive_classes.columns = ['type', 'class_0', 'class_1']\n",
    "    data_cross_quads = transitive_classes.reset_index(drop=True)\n",
    "\n",
    "    res = prepare_crossclass_data(data_subclass_train,data_subclass_train_quads,0,\n",
    "                            data_type_train,1,\n",
    "                           transitive_classes,tc1='class',tc2='subClass',\n",
    "                              ac1='class',ac2='type',\n",
    "                              qc1='class_0',qc2='class_1',qc3='class_2',\n",
    "                              cc1='type',cc2='class_0',cc3='class_1')\n",
    "\n",
    "    node_dict, node_count, train_trips, train_quads = res\n",
    "\n",
    "    df_test= load_clg_files(path+test_file)\n",
    "\n",
    "\n",
    "    data_subclass_test = df_test[df_test['p']== '<http://www.w3.org/2000/01/rdf-schema#subClassOf>']\n",
    "    data_subclass_test= data_subclass_test[['s','o']].rename(columns={'s':'subClass','o':'class'})\n",
    "\n",
    "    res = prepare_subclass_data(data_subclass_train,data_subclass_train_quads)\n",
    "    _, _, test_trips1, test_quads1 = res\n",
    "\n",
    "    data_type_test = df_test[df_test['p']== '<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>']\n",
    "    data_type_test= data_type_test[['s','o']].rename(columns={'s':'type','o':'class'})\n",
    "\n",
    "    _, _, test_trips2, test_quads2 = prepare_subclass_data(data_type_test,tc1='class',\n",
    "                                    tc2='type')\n",
    "\n",
    "\n",
    "    test_trips = test_trips1 + test_trips2\n",
    "\n",
    "\n",
    "    print(len(train_trips),len(test_trips))\n",
    "    \n",
    "    \n",
    "    ## tarin TransE\n",
    "    #print('')\n",
    "    #model_ORE_TransE  = TransE(node_count,2)\n",
    "    #model_ORE_TransE._train(train_trips,train_quads);\n",
    "    #model_ORE_TransE._eval(test_trips[:max_test_batch_size]) # evaluate TransE\n",
    "    \n",
    "    # train rTransE\n",
    "    model_ORE_rTransE  = rTransE(node_count,2)\n",
    "    model_ORE_rTransE._train(train_trips,train_quads,num_epoches=200);\n",
    "    model_ORE_rTransE._eval(test_trips[:max_test_batch_size])  # evaluate RTransE\n",
    "    \n",
    "    env   = Env(train_trips)\n",
    "    agent = DQN_Network([60, 64, 2],lr=1e-3)\n",
    "    agent_samples = agent.train(env,\n",
    "            model_ORE_rTransE.entity_embds.detach().numpy(),\n",
    "            model_ORE_rTransE.rel_embds.detach().numpy(),\n",
    "            episodes = 20000)\n",
    "    \n",
    "    unique_agent_samples = process_agent_samples(train_quads,agent_samples)\n",
    "    updated_train_trips  = train_trips+unique_agent_samples\n",
    "    \n",
    "    update_train_trips = train_trips+unique_agent_samples\n",
    "    model_ORE_rTransE._train(update_train_trips,train_quads,num_epoches=100);\n",
    "    model_ORE_rTransE._eval(test_trips[:max_test_batch_size])  # evaluate RTransE\n",
    "    \n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "LEUOb0_6s3h6",
    "dOkdVChrJ6l_"
   ],
   "name": "CaLiGraph_subclass_reasoner_0.2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
