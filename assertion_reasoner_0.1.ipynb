{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5198,
     "status": "ok",
     "timestamp": 1659360940014,
     "user": {
      "displayName": "Shervin Mehryar",
      "userId": "08841599095409768379"
     },
     "user_tz": -120
    },
    "id": "2wnUipHPEd91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shervin/opt/anaconda3/envs/UM/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import  os\n",
    "import  re\n",
    "import glob\n",
    "\n",
    "import  pandas as pd\n",
    "import  numpy as np\n",
    "\n",
    "from src.utils import *\n",
    "from src.models import TransE, rTransE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OWL2Bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running... _train_OWL2Bench1 _test_OWL2Bench1\n",
      "7989 157\n",
      "\n",
      "epoch 0,\t train loss 0.93\n",
      "epoch 50,\t train loss 1.21\n",
      "epoch 100,\t train loss 1.02\n",
      "hits@1  tensor(0.0039) ,hits@10  tensor(0.1231) ,MR  tensor(37.9864) ,MRR  tensor(0.0552)\n",
      "epoch 0,\t train loss 8.82\n",
      "epoch 50,\t train loss 5.68\n",
      "epoch 150,\t train loss 4.58\n",
      "epoch 200,\t train loss 1.12\n",
      "epoch 250,\t train loss 4.32\n",
      "hits@1  tensor(0.3868) ,hits@10  tensor(0.5707) ,MR  tensor(19.8327) ,MRR  tensor(0.4475)\n",
      "\n",
      "Running... _train_OWL2Bench2 _test_OWL2Bench2\n",
      "15526 146\n",
      "\n",
      "epoch 0,\t train loss 1.00\n",
      "epoch 100,\t train loss 1.01\n",
      "hits@1  tensor(0.0023) ,hits@10  tensor(0.1688) ,MR  tensor(53.0631) ,MRR  tensor(0.0532)\n",
      "epoch 50,\t train loss 4.45\n",
      "epoch 100,\t train loss 3.88\n",
      "epoch 150,\t train loss 0.95\n",
      "epoch 200,\t train loss 1.00\n",
      "hits@1  tensor(0.2042) ,hits@10  tensor(0.3063) ,MR  tensor(40.5172) ,MRR  tensor(0.2551)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OWL2Bench_dbs = [ { 'path' : './datasets/OWL2Bench/OWL2Bench1/',\n",
    "                'train_file'  :'_train_OWL2Bench1',\n",
    "                'test_file' : '_test_OWL2Bench1'},\n",
    "                 { 'path' : './datasets/OWL2Bench/OWL2Bench2/',\n",
    "                'train_file'  :'_train_OWL2Bench2',\n",
    "                'test_file' : '_test_OWL2Bench2'} ]\n",
    "\n",
    "\n",
    "for db_ in OWL2Bench_dbs:\n",
    "    \n",
    "    path = db_['path']\n",
    "    train_file= db_['train_file']\n",
    "    test_file= db_['test_file']\n",
    "    \n",
    "    print('Running...', train_file, test_file)\n",
    "    \n",
    "    # load data\n",
    "    df_train= load_ore_files(path+train_file)\n",
    "    data_subclass_train = df_train[df_train['p']== 'ClassAssertion']\n",
    "    data_subclass_train= data_subclass_train[['s','o']].rename(columns={'s':'class','o':'assertion'})\n",
    "    transitive_classes= pd.merge(data_subclass_train,\n",
    "                                 data_subclass_train,\n",
    "                                 how='right',right_on=['class'],left_on=['assertion']).dropna(subset=['class_x'])\n",
    "    del transitive_classes['class_y']\n",
    "    transitive_classes.columns = ['class_0', 'class_1', 'assertion']\n",
    "    transitive_classes = transitive_classes.drop_duplicates(subset=['class_0', 'class_1', 'assertion']) \n",
    "    data_subclass_train_quads = transitive_classes.reset_index(drop=True)\n",
    "\n",
    "    df_test= load_ore_files(path+test_file)\n",
    "    data_subclass_test = df_test[df_test['p']== 'ClassAssertion']\n",
    "    data_subclass_test= data_subclass_test[['s','o']].rename(columns={'s':'class','o':'assertion'})\n",
    "\n",
    "    res = prepare_subclass_data(data_subclass_train,data_subclass_train_quads,\n",
    "                                tc1='class',\n",
    "                                tc2='assertion',\n",
    "                                qc1='assertion',\n",
    "                                qc2='class_1',\n",
    "                                qc3='class_0')\n",
    "    node_dict, node_count, train_trips, train_quads = res\n",
    "    res = prepare_subclass_data(data_subclass_test,transitive_classes=None,tc1='class',\n",
    "                                tc2='assertion')\n",
    "    _, _, test_trips, test_quads = res\n",
    "    print(len(train_trips),len(train_quads))\n",
    "    \n",
    "    # tarin TransE\n",
    "    print('')\n",
    "    model_ORE_TransE  = TransE(node_count,1)\n",
    "    model_ORE_TransE._train(train_trips,train_quads);\n",
    "\n",
    "    model_ORE_TransE._eval(test_trips) # evaluate TransE\n",
    "    \n",
    "    # train rTransE\n",
    "    model_ORE_rTransE  = rTransE(node_count,1)\n",
    "    model_ORE_rTransE._train(train_trips,train_quads,num_epoches=300);\n",
    "    model_ORE_rTransE._eval(test_trips)  # evaluate RTransE\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORE_dbs = [     { 'path'      : './datasets/ORE/ORE1/',\n",
    "                'train_file'  : '_train_ORE1',\n",
    "                'test_file'   : '_test_ORE1'},\n",
    "                { 'path'      : './datasets/ORE/ORE2/',\n",
    "                'train_file'  : '_train_ORE2',\n",
    "                'test_file'   : '_test_ORE2'},\n",
    "                { 'path'      : './datasets/ORE/ORE3/',\n",
    "                'train_file'  : '_train_ORE3',\n",
    "                'test_file'   : '_test_ORE3'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running... _train_ORE1 _test_ORE1\n",
      "53048 42851\n",
      "\n",
      "epoch 0,\t train loss 0.99\n",
      "epoch 50,\t train loss 1.10\n",
      "epoch 100,\t train loss 1.03\n",
      "hits@1  tensor(0.0071) ,hits@10  tensor(0.1456) ,MR  tensor(43.3990) ,MRR  tensor(0.0589)\n",
      "epoch 0,\t train loss 5.09\n",
      "epoch 50,\t train loss 11.33\n",
      "epoch 100,\t train loss 10.52\n",
      "epoch 150,\t train loss 9.19\n",
      "epoch 200,\t train loss 7.76\n",
      "hits@1  tensor(0.1248) ,hits@10  tensor(0.3693) ,MR  tensor(31.8564) ,MRR  tensor(0.2076)\n",
      "\n",
      "Running... _train_ORE2 _test_ORE2\n",
      "53081 42432\n",
      "\n",
      "epoch 0,\t train loss 1.00\n",
      "epoch 50,\t train loss 1.13\n",
      "epoch 100,\t train loss 0.95\n",
      "hits@1  tensor(0.0070) ,hits@10  tensor(0.0919) ,MR  tensor(51.0719) ,MRR  tensor(0.0465)\n",
      "epoch 0,\t train loss 11.47\n",
      "epoch 50,\t train loss 9.91\n",
      "epoch 150,\t train loss 6.70\n",
      "epoch 200,\t train loss 6.29\n",
      "hits@1  tensor(0.0437) ,hits@10  tensor(0.1728) ,MR  tensor(43.3212) ,MRR  tensor(0.0965)\n",
      "\n",
      "Running... _train_ORE3 _test_ORE3\n",
      "53014 43181\n",
      "\n",
      "epoch 0,\t train loss 0.98\n",
      "epoch 50,\t train loss 1.25\n",
      "epoch 100,\t train loss 1.02\n",
      "hits@1  tensor(0.0065) ,hits@10  tensor(0.1238) ,MR  tensor(49.3344) ,MRR  tensor(0.0527)\n",
      "epoch 50,\t train loss 9.15\n",
      "epoch 100,\t train loss 7.02\n",
      "epoch 150,\t train loss 6.26\n",
      "epoch 250,\t train loss 3.85\n",
      "hits@1  tensor(0.0970) ,hits@10  tensor(0.2845) ,MR  tensor(37.7915) ,MRR  tensor(0.1674)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for db_ in ORE_dbs:\n",
    "    \n",
    "    path = db_['path']\n",
    "    train_file= db_['train_file']\n",
    "    test_file= db_['test_file']\n",
    "    \n",
    "    print('Running...', train_file, test_file)\n",
    "    \n",
    "    # load data\n",
    "    df_train= load_ore_files(path+train_file)\n",
    "    data_subclass_train = df_train[df_train['p']== 'ClassAssertion']\n",
    "    data_subclass_train= data_subclass_train[['s','o']].rename(columns={'s':'class','o':'assertion'})\n",
    "    transitive_classes= pd.merge(data_subclass_train,\n",
    "                                 data_subclass_train,\n",
    "                                 how='right',right_on=['class'],left_on=['assertion']).dropna(subset=['class_x'])\n",
    "    del transitive_classes['class_y']\n",
    "    transitive_classes.columns = ['class_0', 'class_1', 'assertion']\n",
    "    transitive_classes = transitive_classes.drop_duplicates(subset=['class_0', 'class_1', 'assertion']) \n",
    "    data_subclass_train_quads = transitive_classes.reset_index(drop=True)\n",
    "\n",
    "    df_test= load_ore_files(path+test_file)\n",
    "    data_subclass_test = df_test[df_test['p']== 'ClassAssertion']\n",
    "    data_subclass_test= data_subclass_test[['s','o']].rename(columns={'s':'class','o':'assertion'})\n",
    "\n",
    "    res = prepare_subclass_data(data_subclass_train,data_subclass_train_quads,\n",
    "                                tc1='class',\n",
    "                                tc2='assertion',\n",
    "                                qc1='assertion',\n",
    "                                qc2='class_1',\n",
    "                                qc3='class_0')\n",
    "    node_dict, node_count, train_trips, train_quads = res\n",
    "    res = prepare_subclass_data(data_subclass_test,transitive_classes=None,tc1='class',\n",
    "                                tc2='assertion')\n",
    "    _, _, test_trips, test_quads = res\n",
    "    print(len(train_trips),len(train_quads))\n",
    "    \n",
    "    # tarin TransE\n",
    "    print('')\n",
    "    model_ORE_TransE  = TransE(node_count,1)\n",
    "    model_ORE_TransE._train(train_trips,train_quads);\n",
    "\n",
    "    model_ORE_TransE._eval(test_trips) # evaluate TransE\n",
    "    \n",
    "    # train rTransE\n",
    "    model_ORE_rTransE  = rTransE(node_count,1)\n",
    "    model_ORE_rTransE._train(train_trips,train_quads,num_epoches=300);\n",
    "    model_ORE_rTransE._eval(test_trips)  # evaluate RTransE\n",
    "    \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CaLiGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLG_dbs = [ { 'path'      : 'datasets/clg/clg_10e4/',\n",
    "                'train_file'  : 'clg_10e4-train.nt',\n",
    "                'test_file'   : 'clg_10e4-test.nt-e'},\n",
    "            { 'path'      : 'datasets/clg/clg_10e5/',\n",
    "                'train_file'  : 'clg_10e5-train.nt',\n",
    "                'test_file'   : 'clg_10e5-test.nt'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_test_batch_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running... clg_10e4-train.nt clg_10e4-test.nt-e\n",
      "51577 59923\n",
      "\n",
      "epoch 0,\t train loss 0.85\n",
      "epoch 100,\t train loss 1.09\n",
      "hits@1  tensor(0.0164) ,hits@10  tensor(0.1731) ,MR  tensor(41.7982) ,MRR  tensor(0.0739)\n",
      "epoch 50,\t train loss 13.32\n",
      "epoch 100,\t train loss 11.97\n",
      "epoch 200,\t train loss 9.05\n",
      "epoch 250,\t train loss 7.41\n",
      "hits@1  tensor(0.4237) ,hits@10  tensor(0.6039) ,MR  tensor(20.1118) ,MRR  tensor(0.4994)\n",
      "\n",
      "Running... clg_10e5-train.nt clg_10e5-test.nt\n",
      "29973 143\n",
      "\n",
      "epoch 50,\t train loss 1.18\n",
      "epoch 100,\t train loss 1.04\n",
      "hits@1  tensor(0.0079) ,hits@10  tensor(0.0914) ,MR  tensor(47.1705) ,MRR  tensor(0.0503)\n",
      "epoch 50,\t train loss 3.53\n",
      "epoch 100,\t train loss 0.94\n",
      "epoch 150,\t train loss 0.96\n",
      "epoch 200,\t train loss 1.02\n",
      "epoch 250,\t train loss 1.04\n",
      "hits@1  tensor(0.0173) ,hits@10  tensor(0.0953) ,MR  tensor(54.0183) ,MRR  tensor(0.0561)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for db_ in CLG_dbs:\n",
    "    path = db_['path']\n",
    "    train_file= db_['train_file']\n",
    "    test_file= db_['test_file']\n",
    "    \n",
    "    print('Running...', train_file, test_file)\n",
    "    \n",
    "    df_train= load_clg_files(path+train_file)\n",
    "    data_subclass_train = df_train[df_train['p']== '<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>']\n",
    "    data_subclass_train = data_subclass_train[['s','o']].rename(columns={'s':'type','o':'class'})   \n",
    "    transitive_classes= pd.merge(data_subclass_train,data_subclass_train,\n",
    "                                 how='left',right_on=['type'],\n",
    "                                 left_on=['class']).dropna(subset=['class_y'])\n",
    "    del transitive_classes['class_x']\n",
    "\n",
    "\n",
    "    transitive_classes.columns = ['type_0', 'class_0', 'class_1']\n",
    "    transitive_classes = transitive_classes.drop_duplicates(subset=['type_0', 'class_0', 'class_1']) # drop duplicates\n",
    "    data_subclass_train_quads = transitive_classes.reset_index(drop=True)\n",
    "\n",
    "    res = prepare_subclass_data(data_subclass_train,data_subclass_train_quads,\n",
    "                                tc1='class',\n",
    "                                tc2='type',\n",
    "                                qc1='type_0',\n",
    "                                qc2='class_0',\n",
    "                                qc3='class_1')\n",
    "    node_dict, node_count, train_trips, train_quads = res\n",
    "\n",
    "    df_test= load_clg_files(path+test_file)\n",
    "\n",
    "    data_type_test = df_test[df_test['p']== '<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>']\n",
    "    data_type_test= data_type_test[['s','o']].rename(columns={'s':'type','o':'class'})\n",
    "\n",
    "    _, _, test_trips, test_quads = prepare_subclass_data(data_type_test,tc1='class',\n",
    "                                    tc2='type')\n",
    "\n",
    "    print(len(train_trips),len(train_quads))\n",
    "    \n",
    "    # tarin TransE\n",
    "    print('')\n",
    "    model_ORE_TransE  = TransE(node_count,1)\n",
    "    model_ORE_TransE._train(train_trips,train_quads);\n",
    "\n",
    "    model_ORE_TransE._eval(test_trips[:max_test_batch_size]) # evaluate TransE\n",
    "    \n",
    "    # train rTransE\n",
    "    model_ORE_rTransE  = rTransE(node_count,1)\n",
    "    model_ORE_rTransE._train(train_trips,train_quads,num_epoches=300);\n",
    "    model_ORE_rTransE._eval(test_trips[:max_test_batch_size])  # evaluate RTransE\n",
    "    \n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "LEUOb0_6s3h6",
    "dOkdVChrJ6l_"
   ],
   "name": "CaLiGraph_subclass_reasoner_0.2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
