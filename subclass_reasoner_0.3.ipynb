{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5198,
     "status": "ok",
     "timestamp": 1659360940014,
     "user": {
      "displayName": "Shervin Mehryar",
      "userId": "08841599095409768379"
     },
     "user_tz": -120
    },
    "id": "2wnUipHPEd91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shervin/opt/anaconda3/envs/UM/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import  os\n",
    "import  re\n",
    "import glob\n",
    "\n",
    "import  pandas as pd\n",
    "import  numpy as np\n",
    "\n",
    "from src.utils import *\n",
    "from src.models import TransE, rTransE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZb2-5UImROk"
   },
   "source": [
    "#### OWL2Bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running... _train_OWL2Bench1 _test_OWL2Bench1\n",
      "105 64\n",
      "epoch 0,\t train loss 1.03\n",
      "epoch 50,\t train loss 1.11\n",
      "epoch 100,\t train loss 0.99\n",
      "hits@1  tensor(0.) ,hits@10  tensor(0.2000) ,MR  tensor(31.6333) ,MRR  tensor(0.0866)\n",
      "epoch 0,\t train loss 0.94\n",
      "epoch 100,\t train loss 0.91\n",
      "epoch 150,\t train loss 0.98\n",
      "epoch 200,\t train loss 0.66\n",
      "hits@1  tensor(0.0667) ,hits@10  tensor(0.2667) ,MR  tensor(35.1667) ,MRR  tensor(0.1242)\n",
      "\n",
      "Running... _train_OWL2Bench2 _test_OWL2Bench2\n",
      "105 53\n",
      "epoch 0,\t train loss 1.03\n",
      "epoch 50,\t train loss 0.95\n",
      "epoch 100,\t train loss 0.88\n",
      "hits@1  tensor(0.0667) ,hits@10  tensor(0.2667) ,MR  tensor(35.6333) ,MRR  tensor(0.1203)\n",
      "epoch 50,\t train loss 0.91\n",
      "epoch 100,\t train loss 0.96\n",
      "epoch 150,\t train loss 0.80\n",
      "epoch 200,\t train loss 0.84\n",
      "epoch 250,\t train loss 0.57\n",
      "hits@1  tensor(0.) ,hits@10  tensor(0.3000) ,MR  tensor(30.5667) ,MRR  tensor(0.0911)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OWL2Bench_dbs = [ { 'path' : './datasets/OWL2Bench/OWL2Bench1/',\n",
    "                'train_file'  :'_train_OWL2Bench1',\n",
    "                'test_file' : '_test_OWL2Bench1'},\n",
    "                 { 'path' : './datasets/OWL2Bench/OWL2Bench2/',\n",
    "                'train_file'  :'_train_OWL2Bench2',\n",
    "                'test_file' : '_test_OWL2Bench2'} ]\n",
    "\n",
    "\n",
    "for db_ in OWL2Bench_dbs:\n",
    "    \n",
    "    path = db_['path']\n",
    "    train_file= db_['train_file']\n",
    "    test_file= db_['test_file']\n",
    "    \n",
    "    print('Running...', train_file, test_file)\n",
    "    \n",
    "    # load data\n",
    "    df_train= load_ore_files(path+train_file)\n",
    "    \n",
    "    data_subclass_train = df_train[df_train['p']== 'SubClassOf']\n",
    "    data_subclass_train= data_subclass_train[['s','o']].rename(columns={'s':'subClass','o':'class'})\n",
    "    transitive_classes= pd.merge(data_subclass_train,data_subclass_train,\n",
    "                                 how='left',right_on=['subClass'],left_on=['class']\n",
    "    ).dropna(subset=['class_y'])\n",
    "    del transitive_classes['class_x']\n",
    "    transitive_classes.columns = ['class_0', 'class_1', 'class_2']\n",
    "    transitive_classes = transitive_classes.drop_duplicates(subset=['class_0', 'class_1', 'class_2'])\n",
    "    data_subclass_train_quads = transitive_classes.reset_index(drop=True)\n",
    "    \n",
    "    df_test= load_ore_files(path+test_file)\n",
    "    \n",
    "    data_subclass_test = df_test[df_test['p']== 'SubClassOf']\n",
    "    data_subclass_test= data_subclass_test[['s','o']].rename(columns={'s':'subClass','o':'class'})\n",
    "\n",
    "    \n",
    "    # generate triplets and quadruples\n",
    "    res = prepare_subclass_data(data_subclass_train,data_subclass_train_quads)\n",
    "    node_dict, node_count, train_trips, train_quads = res\n",
    "    _, _, test_trips, test_quads = prepare_subclass_data(data_subclass_test)\n",
    "    print(len(train_trips),len(train_quads))\n",
    "    \n",
    "    # tarin TransE\n",
    "    model_OWL_TransE  = TransE(node_count,1)\n",
    "    model_OWL_TransE._train(train_trips,train_quads);\n",
    "    model_OWL_TransE._eval(test_trips) # evaluate TransE\n",
    "    \n",
    "    # train rTransE\n",
    "    model_OWL_rTransE  = rTransE(node_count,1)\n",
    "    model_OWL_rTransE._train(train_trips,train_quads,num_epoches=300);\n",
    "    model_OWL_rTransE._eval(test_trips)  # evaluate rTransE\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORE_dbs = [     { 'path'      : './datasets/ORE/ORE1/',\n",
    "                'train_file'  : '_train_ORE1',\n",
    "                'test_file'   : '_test_ORE1'},\n",
    "                { 'path'      : './datasets/ORE/ORE2/',\n",
    "                'train_file'  : '_train_ORE2',\n",
    "                'test_file'   : '_test_ORE2'},\n",
    "                { 'path'      : './datasets/ORE/ORE3/',\n",
    "                'train_file'  : '_train_ORE3',\n",
    "                'test_file'   : '_test_ORE3'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running... _train_ORE1 _test_ORE1\n",
      "8194 9073\n",
      "\n",
      "epoch 0,\t train loss 1.10\n",
      "epoch 100,\t train loss 0.99\n",
      "hits@1  tensor(0.0090) ,hits@10  tensor(0.0974) ,MR  tensor(51.2131) ,MRR  tensor(0.0493)\n",
      "epoch 0,\t train loss 1.17\n",
      "epoch 50,\t train loss 1.04\n",
      "epoch 100,\t train loss 1.06\n",
      "epoch 250,\t train loss 0.91\n",
      "hits@1  tensor(0.0085) ,hits@10  tensor(0.0854) ,MR  tensor(50.3454) ,MRR  tensor(0.0476)\n",
      "\n",
      "Running... _train_ORE2 _test_ORE2\n",
      "8204 9369\n",
      "\n",
      "epoch 0,\t train loss 0.95\n",
      "epoch 50,\t train loss 1.10\n",
      "hits@1  tensor(0.0090) ,hits@10  tensor(0.1003) ,MR  tensor(51.5712) ,MRR  tensor(0.0514)\n",
      "epoch 50,\t train loss 1.12\n",
      "epoch 100,\t train loss 1.15\n",
      "epoch 150,\t train loss 1.03\n",
      "epoch 200,\t train loss 0.99\n",
      "hits@1  tensor(0.0090) ,hits@10  tensor(0.0926) ,MR  tensor(50.0546) ,MRR  tensor(0.0495)\n",
      "\n",
      "Running... _train_ORE3 _test_ORE3\n",
      "8187 9122\n",
      "\n",
      "epoch 0,\t train loss 1.08\n",
      "epoch 50,\t train loss 1.03\n",
      "epoch 100,\t train loss 1.05\n",
      "hits@1  tensor(0.0064) ,hits@10  tensor(0.1085) ,MR  tensor(50.4748) ,MRR  tensor(0.0503)\n",
      "epoch 50,\t train loss 1.05\n",
      "epoch 100,\t train loss 1.06\n",
      "epoch 200,\t train loss 1.01\n",
      "epoch 250,\t train loss 0.98\n",
      "hits@1  tensor(0.0124) ,hits@10  tensor(0.1167) ,MR  tensor(49.0962) ,MRR  tensor(0.0572)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for db_ in ORE_dbs:\n",
    "    \n",
    "    path = db_['path']\n",
    "    train_file= db_['train_file']\n",
    "    test_file= db_['test_file']\n",
    "    \n",
    "    print('Running...', train_file, test_file)\n",
    "    \n",
    "    # load data\n",
    "    df_train= load_ore_files(path+train_file)\n",
    "    data_subclass_train = df_train[df_train['p']== 'SubClassOf']\n",
    "    data_subclass_train= data_subclass_train[['s','o']].rename(columns={'s':'subClass','o':'class'})\n",
    "    transitive_classes= pd.merge(data_subclass_train,\n",
    "                                 data_subclass_train,\n",
    "                                 how='left',right_on=['subClass'],left_on=['class']\n",
    "    ).dropna(subset=['class_y'])\n",
    "    del transitive_classes['class_x']\n",
    "    transitive_classes.columns = ['class_0', 'class_1', 'class_2']\n",
    "    transitive_classes = transitive_classes.drop_duplicates(subset=['class_0', 'class_1', 'class_2']) \n",
    "    data_subclass_train_quads = transitive_classes.reset_index(drop=True)\n",
    "    \n",
    "    df_test= load_ore_files(path+test_file)\n",
    "    data_subclass_test = df_test[df_test['p']== 'SubClassOf']\n",
    "    data_subclass_test= data_subclass_test[['s','o']].rename(columns={'s':'subClass','o':'class'})\n",
    "    data_subclass_test.head()\n",
    "    \n",
    "    res = prepare_subclass_data(data_subclass_train,data_subclass_train_quads)\n",
    "    node_dict, node_count, train_trips, train_quads = res\n",
    "    _, _, test_trips, test_quads = prepare_subclass_data(data_subclass_test)\n",
    "    print(len(train_trips),len(train_quads))\n",
    "    \n",
    "    # tarin TransE\n",
    "    print('')\n",
    "    model_ORE_TransE  = TransE(node_count,1)\n",
    "    model_ORE_TransE._train(train_trips,train_quads);\n",
    "\n",
    "    model_ORE_TransE._eval(test_trips) # evaluate TransE\n",
    "    \n",
    "    # train rTransE\n",
    "    model_ORE_rTransE  = rTransE(node_count,1)\n",
    "    model_ORE_rTransE._train(train_trips,train_quads,num_epoches=300);\n",
    "    model_ORE_rTransE._eval(test_trips)  # evaluate RTransE\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ny1tbSa2Lk-f"
   },
   "source": [
    "#### CaLiGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLG_dbs = [ { 'path'      : 'datasets/clg/clg_10e4/',\n",
    "                'train_file'  : 'clg_10e4-train.nt',\n",
    "                'test_file'   : 'clg_10e4-test.nt'},\n",
    "            { 'path'      : 'datasets/clg/clg_10e5/',\n",
    "                'train_file'  : 'clg_10e5-train.nt',\n",
    "                'test_file'   : 'clg_10e5-test.nt'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_test_batch_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running... clg_10e4-train.nt clg_10e4-test.nt\n",
      "59956 87509\n",
      "\n",
      "epoch 0,\t train loss 1.10\n",
      "epoch 50,\t train loss 0.90\n",
      "hits@1  tensor(0.) ,hits@10  tensor(0.) ,MR  tensor(24.) ,MRR  tensor(0.0417)\n",
      "epoch 0,\t train loss 11.88\n",
      "epoch 50,\t train loss 10.33\n",
      "epoch 100,\t train loss 8.90\n",
      "hits@1  tensor(1.) ,hits@10  tensor(1.) ,MR  tensor(1.) ,MRR  tensor(1.)\n",
      "\n",
      "Running... clg_10e5-train.nt clg_10e5-test.nt\n",
      "96273 1858\n",
      "\n",
      "epoch 0,\t train loss 0.91\n",
      "epoch 50,\t train loss 1.01\n",
      "epoch 100,\t train loss 0.89\n",
      "hits@1  tensor(0.0021) ,hits@10  tensor(0.0356) ,MR  tensor(67.1800) ,MRR  tensor(0.0259)\n",
      "epoch 0,\t train loss 4.07\n",
      "epoch 50,\t train loss 1.34\n",
      "epoch 100,\t train loss 2.78\n",
      "hits@1  tensor(0.6780) ,hits@10  tensor(0.7128) ,MR  tensor(16.8881) ,MRR  tensor(0.6933)\n",
      "\n",
      "Running... clg_full-train.nt clg_full-val.nt\n"
     ]
    }
   ],
   "source": [
    "for db_ in CLG_dbs:\n",
    "    \n",
    "    path = db_['path']\n",
    "    train_file= db_['train_file']\n",
    "    test_file= db_['test_file']\n",
    "    \n",
    "    print('Running...', train_file, test_file)\n",
    "    \n",
    "    df_train= load_clg_files(path+train_file)\n",
    "    data_subclass_train = df_train[df_train['p']== '<http://www.w3.org/2000/01/rdf-schema#subClassOf>']\n",
    "    data_subclass_train = data_subclass_train[['s','o']].rename(columns={'s':'subClass','o':'class'})   \n",
    "    transitive_classes= pd.merge(data_subclass_train,data_subclass_train,how='left',right_on=['subClass'],left_on=['class']).dropna(subset=['class_y'])\n",
    "    del transitive_classes['class_x']\n",
    "    transitive_classes.columns = ['class_0', 'class_1', 'class_2']\n",
    "    transitive_classes = transitive_classes.drop_duplicates(subset=['class_0', 'class_1', 'class_2']) # drop duplicates\n",
    "    data_subclass_train_quads = transitive_classes.reset_index(drop=True)\n",
    "    \n",
    "    df_test= load_clg_files(path+test_file)\n",
    "    data_subclass_test = df_test[df_test['p']== '<http://www.w3.org/2000/01/rdf-schema#subClassOf>']\n",
    "    data_subclass_test= data_subclass_test[['s','o']].rename(columns={'s':'subClass','o':'class'})\n",
    "    \n",
    "    res = prepare_subclass_data(data_subclass_train,data_subclass_train_quads)\n",
    "    ode_dict, node_count, train_trips, train_quads = res\n",
    "    _, _, test_trips, test_quads = prepare_subclass_data(data_subclass_test)\n",
    "    print(len(train_trips),len(train_quads))\n",
    "    \n",
    "    # Train TransE\n",
    "    print('')\n",
    "    model_e  = TransE(node_count,1)\n",
    "    model_e._train(train_trips,train_quads);\n",
    "    model_e._eval(test_trips[:max_test_batch_size])  # evaluate TransE\n",
    "    \n",
    "    # Train rTransE\n",
    "    model_r  = rTransE(node_count,1)\n",
    "    model_r._train(train_trips,train_quads);\n",
    "    model_r._eval(test_trips[:max_test_batch_size]) # evaluate rTransE\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traind_df = load_clg_zfiles('./datasets/clg/clg_full/clg_full-train.nt.gz')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "LEUOb0_6s3h6",
    "dOkdVChrJ6l_"
   ],
   "name": "CaLiGraph_subclass_reasoner_0.2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
