{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f5e43c3-b1df-4483-af3f-963349d1986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  os\n",
    "import  re\n",
    "import  glob\n",
    "\n",
    "import  pandas as pd\n",
    "import  numpy  as np\n",
    "\n",
    "from src.utils  import *\n",
    "from src.models import TransE, rTransE\n",
    "\n",
    "from src.env   import Env\n",
    "from src.agent import DQN_Network, process_agent_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc163d9e-1164-4b94-9f77-638a80e1a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clg_zfiles(pathfilename):\n",
    "    \n",
    "    #nt_file = open(pathfilename,'r')\n",
    "    lines =[]\n",
    "    with gzip.open(pathfilename,'r') as fin: \n",
    "        all_lines = fin.readline()\n",
    "        lines= all_lines.decode('utf8').split(' .')\n",
    "    \n",
    "    num_lines = 0\n",
    "    clg_dict  = dict({'s':[],'o':[],'p':[]})\n",
    "    \n",
    "    for i,line in enumerate(lines):\n",
    "        num_lines+=1\n",
    "        entities = line.split(' ')\n",
    "        if len(entities) != 3: continue\n",
    "        clg_dict['s'].append(entities[0])\n",
    "        clg_dict['p'].append(entities[1])\n",
    "        clg_dict['o'].append(entities[2])\n",
    "        \n",
    "    df = pd.DataFrame(clg_dict)\n",
    "        \n",
    "    #print(num_lines)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7374a3ae-bc5c-4878-a55d-85778de91d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path      = 'datasets/clg/clg_full/'\n",
    "train_file= 'clg_full-train.nt.gz'\n",
    "test_file = 'clg_full-test.nt.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d61a45e1-842a-47bf-a799-1b96095e26d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= load_clg_zfiles(path+train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e944df17-45e4-4875-8862-73b571c7c975",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = load_clg_zfiles(path+test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "863bb33e-565f-4f7d-83ae-68a52995da46",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_test_batch_size=-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55e67d7-4756-456b-9cd2-a6d53c3c948d",
   "metadata": {},
   "source": [
    "### Subclass Relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e57a4ed-5b94-40cb-acd6-e6c8cb5c2f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running...', train_file, test_file)\n",
    "\n",
    "\n",
    "data_subclass_train = df_train[df_train['p']== '<http://www.w3.org/2000/01/rdf-schema#subClassOf>']\n",
    "data_subclass_train = data_subclass_train[['s','o']].rename(columns={'s':'subClass','o':'class'})   \n",
    "transitive_classes= pd.merge(data_subclass_train,data_subclass_train,how='left',right_on=['subClass'],left_on=['class']).dropna(subset=['class_y'])\n",
    "del transitive_classes['class_x']\n",
    "transitive_classes.columns = ['class_0', 'class_1', 'class_2']\n",
    "transitive_classes = transitive_classes.drop_duplicates(subset=['class_0', 'class_1', 'class_2']) # drop duplicates\n",
    "data_subclass_train_quads = transitive_classes.reset_index(drop=True)\n",
    "\n",
    "data_subclass_test = df_test[df_test['p']== '<http://www.w3.org/2000/01/rdf-schema#subClassOf>']\n",
    "data_subclass_test= data_subclass_test[['s','o']].rename(columns={'s':'subClass','o':'class'})\n",
    "\n",
    "res = prepare_subclass_data(data_subclass_train,data_subclass_train_quads)\n",
    "ode_dict, node_count, train_trips, train_quads = res\n",
    "_, _, test_trips, test_quads = prepare_subclass_data(data_subclass_test)\n",
    "print(len(train_trips),len(train_quads))\n",
    "\n",
    "# Train TransE\n",
    "print('')\n",
    "model_e  = TransE(node_count,1)\n",
    "model_e._train(train_trips,train_quads);\n",
    "model_e._eval(test_trips[:max_test_batch_size])  # evaluate TransE\n",
    "\n",
    "# Train rTransE\n",
    "model_r  = rTransE(node_count,1)\n",
    "model_r._train(train_trips,train_quads,num_epoches=300);\n",
    "model_r._eval(test_trips[:max_test_batch_size]) # evaluate rTransE\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ecb4ad-37ac-43d1-8b36-da0e7eeacd47",
   "metadata": {},
   "source": [
    "### Asertation Relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1d21b9-64de-4aec-807a-aa941dede76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running...', train_file, test_file)\n",
    "\n",
    "data_subclass_train = df_train[df_train['p']== '<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>']\n",
    "data_subclass_train = data_subclass_train[['s','o']].rename(columns={'s':'type','o':'class'})   \n",
    "transitive_classes= pd.merge(data_subclass_train,data_subclass_train,\n",
    "                             how='left',right_on=['type'],\n",
    "                             left_on=['class']).dropna(subset=['class_y'])\n",
    "del transitive_classes['class_x']\n",
    "\n",
    "\n",
    "transitive_classes.columns = ['type_0', 'class_0', 'class_1']\n",
    "transitive_classes = transitive_classes.drop_duplicates(subset=['type_0', 'class_0', 'class_1']) # drop duplicates\n",
    "data_subclass_train_quads = transitive_classes.reset_index(drop=True)\n",
    "\n",
    "res = prepare_subclass_data(data_subclass_train,data_subclass_train_quads,\n",
    "                            tc1='class',\n",
    "                            tc2='type',\n",
    "                            qc1='type_0',\n",
    "                            qc2='class_0',\n",
    "                            qc3='class_1')\n",
    "node_dict, node_count, train_trips, train_quads = res\n",
    "\n",
    "data_type_test = df_test[df_test['p']== '<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>']\n",
    "data_type_test= data_type_test[['s','o']].rename(columns={'s':'type','o':'class'})\n",
    "\n",
    "_, _, test_trips, test_quads = prepare_subclass_data(data_type_test,tc1='class',\n",
    "                                tc2='type')\n",
    "\n",
    "print(len(train_trips),len(train_quads))\n",
    "\n",
    "# tarin TransE\n",
    "print('')\n",
    "model_TransE  = TransE(node_count,1)\n",
    "model_TransE._train(train_trips,train_quads);\n",
    "\n",
    "model_TransE._eval(test_trips) # evaluate TransE\n",
    "\n",
    "# train rTransE\n",
    "model_rTransE  = rTransE(node_count,1)\n",
    "model_rTransE._train(train_trips,train_quads,num_epoches=300);\n",
    "model_rTransE._eval(test_trips[:max_test_batch_size])  # evaluate RTransE\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a93d5-071b-4529-8f59-c07ed9966a5b",
   "metadata": {},
   "source": [
    "### Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895096f-4108-46cb-97bd-a3cda556d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running...', train_file, test_file)\n",
    "\n",
    "data_subclass_train = df_train[df_train['p']== '<http://www.w3.org/2000/01/rdf-schema#subClassOf>']\n",
    "data_subclass_train = data_subclass_train[['s','o']].rename(columns={'s':'subClass','o':'class'})   \n",
    "transitive_classes= pd.merge(data_subclass_train,data_subclass_train,how='left',\n",
    "                             right_on=['subClass'],left_on=['class']).dropna(subset=['class_y'])\n",
    "del transitive_classes['class_x']\n",
    "transitive_classes.columns = ['class_0', 'class_1', 'class_2']\n",
    "transitive_classes = transitive_classes.drop_duplicates(subset=['class_0', 'class_1', 'class_2']) # drop duplicates\n",
    "data_subclass_train_quads = transitive_classes.reset_index(drop=True)\n",
    "\n",
    "data_type_train = df_train[df_train['p']== '<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>']\n",
    "data_type_train = data_type_train[['s','o']].rename(columns={'s':'type','o':'class'})   \n",
    "\n",
    "transitive_classes = pd.merge(data_type_train,data_subclass_train,\n",
    "                                 how='left',left_on=['class'],right_on=['subClass']).dropna(subset=['class_y'])\n",
    "del transitive_classes['class_x']\n",
    "transitive_classes.columns = ['type', 'class_0', 'class_1']\n",
    "data_cross_quads = transitive_classes.reset_index(drop=True)\n",
    "\n",
    "res = prepare_crossclass_data(data_subclass_train,data_subclass_train_quads,0,\n",
    "                        data_type_train,1,\n",
    "                       transitive_classes,tc1='class',tc2='subClass',\n",
    "                          ac1='class',ac2='type',\n",
    "                          qc1='class_0',qc2='class_1',qc3='class_2',\n",
    "                          cc1='type',cc2='class_0',cc3='class_1')\n",
    "\n",
    "node_dict, node_count, train_trips, train_quads = res\n",
    "\n",
    "\n",
    "data_subclass_test = df_test[df_test['p']== '<http://www.w3.org/2000/01/rdf-schema#subClassOf>']\n",
    "data_subclass_test= data_subclass_test[['s','o']].rename(columns={'s':'subClass','o':'class'})\n",
    "\n",
    "res = prepare_subclass_data(data_subclass_train,data_subclass_train_quads)\n",
    "_, _, test_trips1, test_quads1 = res\n",
    "\n",
    "data_type_test = df_test[df_test['p']== '<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>']\n",
    "data_type_test= data_type_test[['s','o']].rename(columns={'s':'type','o':'class'})\n",
    "\n",
    "_, _, test_trips2, test_quads2 = prepare_subclass_data(data_type_test,tc1='class',\n",
    "                                tc2='type')\n",
    "\n",
    "\n",
    "test_trips = test_trips1 + test_trips2\n",
    "\n",
    "\n",
    "print(len(train_trips),len(test_trips))\n",
    "\n",
    "\n",
    "# tarin TransE\n",
    "print('')\n",
    "model_TransE  = TransE(node_count,2)\n",
    "model_TransE._train(train_trips,train_quads);\n",
    "model_TransE._eval(test_trips[:max_test_batch_size]) # evaluate TransE\n",
    "\n",
    "# train rTransE\n",
    "model_rTransE  = rTransE(node_count,2)\n",
    "model_rTransE._train(train_trips,train_quads,num_epoches=200);\n",
    "model_rTransE._eval(test_trips[:max_test_batch_size])  # evaluate RTransE\n",
    "\n",
    "\n",
    "env   = Env(train_trips)\n",
    "agent = DQN_Network([60, 64, 2],lr=1e-3)\n",
    "agent_samples = agent.train(env,\n",
    "        model_rTransE.entity_embds.detach().numpy(),\n",
    "        model_rTransE.rel_embds.detach().numpy(),\n",
    "        episodes = 20000)\n",
    "\n",
    "unique_agent_samples = process_agent_samples(train_quads,agent_samples)\n",
    "updated_train_trips  = train_trips+unique_agent_samples\n",
    "\n",
    "update_train_trips = train_trips+unique_agent_samples\n",
    "model_rTransE._train(update_train_trips,train_quads,num_epoches=100);\n",
    "model_rTransE._eval(test_trips[:max_test_batch_size])  # evaluate aTransE\n",
    "\n",
    "print()\n",
    "\n",
    "env   = Env(train_trips)\n",
    "agent = DQN_Network([60, 64, 2],lr=1e-3)\n",
    "agent_samples = agent.train(env,\n",
    "        model_rTransE.entity_embds.detach().numpy(),\n",
    "        model_rTransE.rel_embds.detach().numpy(),\n",
    "        episodes = 20000)\n",
    "\n",
    "unique_agent_samples = process_agent_samples(train_quads,agent_samples)\n",
    "updated_train_trips  = train_trips+unique_agent_samples\n",
    "\n",
    "update_train_trips = train_trips+unique_agent_samples\n",
    "model_rTransE._train(update_train_trips,train_quads,num_epoches=100);\n",
    "model_rTransE._eval(test_trips[:max_test_batch_size])  # evaluate aTransE\n",
    "\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
